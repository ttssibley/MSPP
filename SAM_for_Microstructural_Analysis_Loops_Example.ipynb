{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp9+fHBotoN2TN3tYa6neZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttssibley/MSPP/blob/main/SAM_for_Microstructural_Analysis_Loops_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMDoMfYPtwFI"
      },
      "outputs": [],
      "source": [
        "#If possible, use GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import cv2\n",
        "from google.colab import files\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, jaccard_score\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "metadata": {
        "id": "IWGlE83Mt7MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)\n",
        "\n",
        "#install segment-anything from github\n",
        "!pip install -q 'git+https://github.com/facebookresearch/segment-anything'\n",
        "!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision\n",
        "\n",
        "!mkdir -p {HOME}/weights\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P {HOME}/weights\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
        "\n",
        "!mkdir -p {HOME}/data\n",
        "!mkdir -p {HOME}/labels\n",
        "!mkdir -p {HOME}/images\n",
        "!mkdir -p {HOME}/masks\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "MODEL_TYPE = \"vit_h\"\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaM9BALOuMLX",
        "outputId": "3f481a0b-6af9-48a7-fa32-0d9b23b27045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOME: /content\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hneew\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(binary_array1, binary_array2):\n",
        "    # Calculate the intersection and union\n",
        "    intersection = np.logical_and(binary_array1, binary_array2)\n",
        "    union = np.logical_or(binary_array1, binary_array2)\n",
        "    # Calculate IoU\n",
        "    iou = np.sum(intersection) / np.sum(union)\n",
        "    return iou\n",
        "\n",
        "def calculate_f1_score(ground_truth, predicted_labels):\n",
        "    eps=1e-10\n",
        "    ground_truth = np.array(ground_truth)\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "    true_positives = np.sum((ground_truth == 1) & (predicted_labels == 1))\n",
        "    false_positives = np.sum((ground_truth == 0) & (predicted_labels == 1))\n",
        "    false_negatives = np.sum((ground_truth == 1) & (predicted_labels == 0))\n",
        "\n",
        "    precision = true_positives / (true_positives + false_positives + eps)\n",
        "    recall = true_positives / (true_positives + false_negatives + eps)\n",
        "\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall + eps)\n",
        "    return f1_score, precision, recall, true_positives, false_positives, false_negatives\n",
        "\n",
        "def make_gt_mask(gt_segmentations, combined_mask):\n",
        "  for segmentation in gt_segmentations:\n",
        "    polygon_np = np.array(segmentation, dtype=np.int32)\n",
        "    polygon_np = polygon_np.reshape((-1, 2))\n",
        "    cv2.fillPoly(combined_mask, [polygon_np], color=(255, 255, 255))\n",
        "\n",
        "  combined_mask[combined_mask==255]=1\n",
        "  return combined_mask\n",
        "\n",
        "\n",
        "def find_particle_centers(binary_array):\n",
        "    contours, _ = cv2.findContours(binary_array.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    centers = []\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        x_c=x+w/2\n",
        "        y_c=y+h/2\n",
        "        centers.append((x_c, y_c))\n",
        "    return centers\n",
        "\n",
        "def parse_line(line):\n",
        "    parts = line.strip().split()\n",
        "    parts = [float(x) for x in parts]\n",
        "    class_label = int(parts[0])\n",
        "    class_label=1\n",
        "    x, y, w, h = map(float, parts[1:])\n",
        "    return class_label, x, y, w, h\n",
        "\n",
        "def generate_bbs_from_txt(txt_file, image_width, image_height):\n",
        "    # Read lines from the txt file\n",
        "    with open(txt_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    bb_gt_yolo=[]\n",
        "\n",
        "    mask = np.zeros((image_height, image_width), dtype=np.uint8)\n",
        "\n",
        "    for line in lines:\n",
        "        # Parse the line\n",
        "        class_label, x, y, w, h = parse_line(line)\n",
        "        class_label, x, y, w, h = parse_line(line)\n",
        "        x,y,w,h=int(x*image_width),int(y*image_height),int(w*image_width),int(h*image_height)\n",
        "\n",
        "        x1 = int(x-w/2)\n",
        "        y1 = int(y-h/2)\n",
        "        x2 = int(x+w/2)\n",
        "        y2 = int(y+h/2)\n",
        "\n",
        "        x1 = np.clip(x1, 0, image_width - 1)\n",
        "        x2 = np.clip(x2, 0, image_width - 1)\n",
        "        y1 = np.clip(y1, 0, image_height - 1)\n",
        "        y2 = np.clip(y2, 0, image_height - 1)\n",
        "\n",
        "        bb_gt_yolo.append((int(x1),int(y1),int(x2),int(y2)))\n",
        "\n",
        "        mask[y1:y2, x1:x2] = class_label\n",
        "    return(bb_gt_yolo, mask)"
      ],
      "metadata": {
        "id": "ivu1LB49vNIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/images'\n",
        "\n",
        "with open(os.path.join(HOME, \"updated_test.json\")) as f: #for updated_test.json, use the file provided by Jacobs. et al\n",
        "    bbox_dictionary = json.load(f)\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "  IMAGE_NAME= filename.split(\".\")[0]\n",
        "  IMAGE_PATH = os.path.join(HOME, \"images\", IMAGE_NAME+\".jpg\")\n",
        "  image_bgr = cv2.imread(IMAGE_PATH)\n",
        "  image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "  grayscale_image = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2GRAY)\n",
        "  bounding_boxes_gt= [item['bbox'] for item in bbox_dictionary[IMAGE_NAME]]\n",
        "  segmentations_gt= [item['segmentation'] for item in bbox_dictionary[IMAGE_NAME]]\n",
        "  bounding_boxes_gt_corrected=[]\n",
        "  image_height, image_width, _ = image_rgb.shape\n",
        "\n",
        "\n",
        "  for segmentation in segmentations_gt:\n",
        "    x_coordinates = segmentation[0][::2]\n",
        "    y_coordinates = segmentation[0][1::2]\n",
        "    width = max(x_coordinates) - min(x_coordinates)\n",
        "    height = max(y_coordinates) - min(y_coordinates)\n",
        "\n",
        "#input thresholds\n",
        "slope_cutoff=1 # example, set as needed\n",
        "area_cutoff=50 # example, set as needed\n",
        "aspect_ratio_cutoff_H=.8 # example, set as needed\n",
        "aspect_ratio_cutoff_L=.1 # example, set as needed\n",
        "circularity_cutoff=.7 # example, set as needed\n",
        "bounding_boxes_gt_tensor=torch.tensor(bounding_boxes_gt_corrected)\n",
        "\n"
      ],
      "metadata": {
        "id": "EE69p71vveGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/images'\n",
        "\n",
        "# input points per side\n",
        "_points_ = 50  # example, set as needed\n",
        "\n",
        "with open(os.path.join(HOME, \"updated_test.json\")) as f: #refer to the Jacobs et al (2022) paper for .json files\n",
        "    bbox_dictionary = json.load(f)\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename == \".ipynb_checkpoints\":\n",
        "        continue\n",
        "\n",
        "    IMAGE_NAME = filename.split(\".\")[0]\n",
        "    IMAGE_PATH = os.path.join(HOME, \"images\", IMAGE_NAME + \".jpg\")\n",
        "    image_bgr = cv2.imread(IMAGE_PATH)\n",
        "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    mask_generator = SamAutomaticMaskGenerator(\n",
        "        model=sam,\n",
        "        points_per_side=_points_,\n",
        "        pred_iou_thresh=0.80, # example, set as needed\n",
        "        stability_score_thresh=0.91, # example, set as needed\n",
        "        crop_n_layers=1,\n",
        "        crop_n_points_downscale_factor=2,\n",
        "        randpoints=False,\n",
        "        min_mask_region_area=50, # example, set as needed\n",
        "    )\n",
        "\n",
        "    bounding_boxes_gt = [item['bbox'] for item in bbox_dictionary[IMAGE_NAME]]\n",
        "    image_height, image_width, _ = image_rgb.shape\n",
        "    bounding_boxes_gt_tensor = torch.tensor(bounding_boxes_gt)\n",
        "\n",
        "    sam_result = mask_generator.generate(image_rgb)\n",
        "\n",
        "    bounding_boxes_predicted = []\n",
        "    bb_dictionary = {}\n",
        "\n",
        "    for count, result in enumerate(sam_result):\n",
        "        x, y, w, h = result['bbox']\n",
        "        x1, y1, x2, y2 = x, y, x + w, y + h\n",
        "        area = result['area']\n",
        "        segmentation = result['segmentation']\n",
        "        pred_iou = result['predicted_iou']\n",
        "\n",
        "        # geometric features\n",
        "        true_indices = [(i, j) for i, row in enumerate(segmentation) for j, val in enumerate(row) if val]\n",
        "        if not true_indices:\n",
        "            continue\n",
        "        x_coordinates = [coord[1] for coord in true_indices]\n",
        "        y_coordinates = [coord[0] for coord in true_indices]\n",
        "        width = max(x_coordinates) - min(x_coordinates)\n",
        "        height = max(y_coordinates) - min(y_coordinates)\n",
        "        aspect_ratio = width / height if height > 0 else 0\n",
        "\n",
        "        currmask = segmentation.astype(np.uint8) * 255\n",
        "        contours, _ = cv2.findContours(currmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        perimeter = cv2.arcLength(contours[0], True) if contours else 0\n",
        "        circularity = perimeter / (math.sqrt((4 * np.pi * area))) if area > 0 else 0\n",
        "\n",
        "\n",
        "        area_cutoff = 5400 # example, set as needed\n",
        "        if area < area_cutoff and aspect_ratio_cutoff_L < aspect_ratio < aspect_ratio_cutoff_H and pred_iou > predicted_iou_cutoff and circularity < circularity_cutoff:\n",
        "            bounding_boxes_predicted.append((x1, y1, x2, y2))\n",
        "            bb_dictionary[count] = {\n",
        "                'bbox': (x1, y1, x2, y2),\n",
        "                'circularity': circularity,\n",
        "                'area': area,\n",
        "                'iou': result['predicted_iou'],\n",
        "                'stability_score': result['stability_score'],\n",
        "                'aspect_ratio': aspect_ratio,\n",
        "                'segmentation': segmentation,\n",
        "            }\n",
        "\n",
        "    bounding_boxes_predicted_tensor = torch.tensor(bounding_boxes_predicted)\n",
        "    iou = torchvision.ops.box_iou(bounding_boxes_predicted_tensor, bounding_boxes_gt_tensor)\n",
        "    iou_scores, _ = torch.max(iou, dim=1)\n",
        "    nms_indices = torchvision.ops.nms(bounding_boxes_predicted_tensor.float(), iou_scores.float(), iou_threshold=0.1)\n",
        "    bounding_boxes_predicted_nms = bounding_boxes_predicted_tensor[nms_indices]\n",
        "\n",
        "    iou = torchvision.ops.box_iou(bounding_boxes_predicted_nms, bounding_boxes_gt_tensor)\n",
        "    iou_array = iou.numpy()\n",
        "\n",
        "    # pixelwise mask\n",
        "    gt_segmentations = [item['segmentation'] for item in bbox_dictionary[IMAGE_NAME]]\n",
        "    gtmask = make_gt_mask(gt_segmentations, np.zeros((image_height, image_width)))\n",
        "    pred_mask = np.zeros((image_height, image_width))\n",
        "    for i in nms_indices.numpy():\n",
        "        seg_arr = np.array(bb_dictionary[i]['segmentation'], dtype=int)\n",
        "        pred_mask += seg_arr\n",
        "    pred_mask[pred_mask > 1] = 1\n",
        "\n",
        "    # object-wise metrics\n",
        "    thresh = 0.1\n",
        "    tps_ow = sum(row.max() > thresh for row in iou_array)\n",
        "    fps_ow = sum(row.max() <= thresh for row in iou_array)\n",
        "    fns_ow = sum(max(iou_array[:, col]) < thresh for col in range(iou_array.shape[1]))\n",
        "\n",
        "    precision_ow = tps_ow / (tps_ow + fps_ow + 1e-9)\n",
        "    recall_ow = tps_ow / (tps_ow + fns_ow + 1e-9)\n",
        "    f1_ow = 2 * (precision_ow * recall_ow) / (precision_ow + recall_ow + 1e-9)\n",
        "\n",
        "    f1_pw, precision_pw, recall_pw, tps_pw, fps_pw, fns_pw = calculate_f1_score(gtmask, pred_mask)\n",
        "\n",
        "    print(IMAGE_NAME, f\"Objectwise F1: {f1_ow:.3f}, Pixelwise F1: {f1_pw:.3f}\")\n",
        "\n",
        "    # visualization\n",
        "    image_with_boxes = image_bgr.copy()\n",
        "    for box in bounding_boxes_predicted_nms.numpy():\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        cv2.rectangle(image_with_boxes, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    image_with_boxes_rgb = cv2.cvtColor(image_with_boxes, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.axis('off')\n",
        "    plt.title(f'{IMAGE_NAME}')\n",
        "    plt.imshow(image_with_boxes_rgb)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "6uINwInZwMH_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}